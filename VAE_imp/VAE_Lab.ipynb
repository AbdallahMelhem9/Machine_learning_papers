{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nn8fUEpELfBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1st Implementation, MNIST Dataset**"
      ],
      "metadata": {
        "id": "P8p9Uie_Ld_x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UVSGgvrGICwe"
      },
      "outputs": [],
      "source": [
        "# -----------------------\n",
        "# 0) Imports & Setup\n",
        "# -----------------------\n",
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import make_grid\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO 0.1: Set the seed and device\n",
        "torch.manual_seed(...)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# ============================================================\n",
        "# PART A — Minimal VAE on MNIST (MLP)\n",
        "# ============================================================\n",
        "\n",
        "# -----------------------\n",
        "# 1) Data (MNIST)\n",
        "# -----------------------\n",
        "torch.manual_seed(0)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "batch_size = 128\n",
        "transform = transforms.ToTensor()\n",
        "train_ds = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WOl2LGCaIKn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# 2) Model (MLP VAE)\n",
        "# -----------------------\n",
        "class VAE(nn.Module):\n",
        "    # TODO A2.0: Decide latent dimension\n",
        "    def __init__(self, z_dim=20):\n",
        "        super().__init__()\n",
        "        # Encoder MLP\n",
        "        # TODO A2.1: Fill input and hidden sizes\n",
        "        self.fc1 = nn.Linear(28*28, ...)\n",
        "        # TODO A2.2: Heads for mean and log-variance\n",
        "        self.fc_mu     = nn.Linear(..., z_dim)\n",
        "        self.fc_logvar = nn.Linear(..., z_dim)\n",
        "\n",
        "        # Decoder MLP\n",
        "        # TODO A2.3: First decoder layer (latent -> hidden)\n",
        "        self.fc3 = nn.Linear(z_dim, ...)\n",
        "        # TODO A2.4: Final decoder layer (hidden -> flattened image)\n",
        "        self.fc4 = nn.Linear(400, ...)  #output size should equal ????\n",
        "\n",
        "    def encode(self, x):\n",
        "        \"\"\"Map x -> (mu, logvar).\"\"\"\n",
        "        # TODO A2.5: Fill the dots\n",
        "        h = F.relu(self.fc1(...))\n",
        "        # TODO A2.6: Return mu and logvar from h\n",
        "        mu = self.fc_mu(...)\n",
        "        logvar = self.fc_logvar(...)\n",
        "        return mu, logvar\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        \"\"\"z = mu + sigma * eps, with eps ~ N(0, I).\"\"\"\n",
        "        # TODO A2.7: Compute std from logvar, sample eps, return z\n",
        "        std = torch.exp(0.5 * ...)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def decode(self, z):\n",
        "        \"\"\"Map z -> x_hat in [0,1].\"\"\"\n",
        "        # TODO A2.8: Implement decoder forward pass\n",
        "        h = F.relu(self.fc3(...))\n",
        "        x_hat = torch.sigmoid(self.fc4(...))\n",
        "        return x_hat\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Full VAE pass.\"\"\"\n",
        "        # TODO A2.9: Flatten x to [B, 784]\n",
        "        x = x.view(..., ...)\n",
        "        mu, logvar = self.encode(...)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        recon = self.decode(z)\n",
        "        return recon, mu, logvar\n",
        "\n",
        "model = VAE(z_dim=20).to(device)\n"
      ],
      "metadata": {
        "id": "vdSbYC-1LG9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# -----------------------\n",
        "# 3) Loss (negative ELBO)\n",
        "# -----------------------\n",
        "def vae_loss(recon, x, mu, logvar):\n",
        "    \"\"\"Use BCE reconstruction + analytic KL.\"\"\"\n",
        "    # TODO A3.1: Ensure shapes match for BCE\n",
        "    b = x.size(0)\n",
        "    x = x.view(b, -1)\n",
        "    # TODO A3.2: Compute BCE with reduction='sum'\n",
        "    bce = F.binary_cross_entropy(..., ..., reduction='sum')\n",
        "    # TODO A3.3: Compute KL = -0.5 * sum(1 + logvar - mu^2 - exp(logvar))\n",
        "    kld = -0.5 * torch.sum(1 + ... - ... - ...)\n",
        "    # TODO A3.4: Return per-example averaged losses (total, bce, kld)\n",
        "    return (... + ...) / b, ... / b, ... / b\n"
      ],
      "metadata": {
        "id": "VPWLvt7OLZ-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# -----------------------\n",
        "# 4) Train (MNIST)\n",
        "# -----------------------\n",
        "# TODO A4.1: Choose epochs and optimizer\n",
        "epochs = ...\n",
        "opt = torch.optim.Adam(model.parameters(), lr=...)\n",
        "\n",
        "model.train()\n",
        "for epoch in range(1, epochs+1):\n",
        "    total, total_bce, total_kld, n = 0.0, 0.0, 0.0, 0\n",
        "    for x, _ in train_loader:\n",
        "        x = x.to(device)\n",
        "        recon, mu, logvar = model(...)\n",
        "        loss, bce, kld = vae_loss(recon, x, mu, logvar)\n",
        "\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "        bs = x.size(0)\n",
        "        total     += loss.item() * bs\n",
        "        total_bce += bce.item()  * bs\n",
        "        total_kld += kld.item()  * bs\n",
        "        n += bs\n",
        "    print(f\"[MNIST][Epoch {epoch:02d}] loss={total/n:.2f} recon={total_bce/n:.2f} kl={total_kld/n:.2f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "VC0dTJ-FLbd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# 5) Visualize (MNIST)\n",
        "# -----------------------\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    # TODO A5.1: Sample z ~ N(0,I) and decode\n",
        "    z = torch.randn(..., ..., device=device)\n",
        "    gen = model.decode(z).view(-1, 1, 28, 28).cpu()\n",
        "    gen_grid = make_grid(gen, nrow=...)\n",
        "\n",
        "    # TODO A5.2: Take a batch, reconstruct\n",
        "    x, _ = next(iter(train_loader))\n",
        "    x = x.to(device)[:...]\n",
        "    recon, _, _ = model(...)\n",
        "    recon = recon.view(-1, 1, 28, 28).cpu()\n",
        "    recon_grid = make_grid(recon, nrow=...)\n",
        "    inp_grid = make_grid(x.view(-1, 1, 28, 28).cpu(), nrow=...)\n",
        "\n",
        "def show(t, title=None):\n",
        "    plt.figure(figsize=(6,6)); plt.axis('off')\n",
        "    if title: plt.title(title)\n",
        "    # TODO A5.3: Permute for HWC and choose cmap for grayscale\n",
        "    plt.imshow(t.permute(..., ..., ...).squeeze(), cmap='gray')\n",
        "\n",
        "show(gen_grid,  \"MNIST Samples (z ~ N(0,I))\")\n",
        "show(inp_grid,  \"MNIST Inputs\")\n",
        "show(recon_grid,\"MNIST Reconstructions\")"
      ],
      "metadata": {
        "id": "ONdfiR_gLcxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "**# PART B — Convolutional VAE on Oxford-IIIT Pet (Cats subset)**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "W1f3AgsDMurW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# -----------------------\n",
        "# 6) Data (Cats subset)\n",
        "# -----------------------\n",
        "# TODO B1.1: Set batch size\n",
        "bs = ...\n",
        "\n",
        "# TODO B1.2: Define transform to 64x64 tensor in [0,1]\n",
        "tx = transforms.Compose([\n",
        "    transforms.Resize(...),  #we want it 64\n",
        "    transforms.CenterCrop(64),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "ds_full = datasets.OxfordIIITPet(root='./data', split='trainval', target_types='category', transform=tx, download=True)\n",
        "cat_names = ['Abyssinian','Bengal','Birman','Bombay','Persian','Ragdoll','Siamese','Sphynx']\n",
        "cat_idx = { ds_full.class_to_idx[n] for n in cat_names }\n",
        "idxs = [ i for i in range(len(ds_full)) if ds_full[i][1] in cat_idx ]\n",
        "ds = Subset(ds_full, idxs)\n",
        "dl=DataLoader(ds,batch_size=bs,shuffle=True,num_workers=2,pin_memory=True)"
      ],
      "metadata": {
        "id": "7H_Suk3sM124"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# -----------------------\n",
        "# 7) Conv VAE Model\n",
        "# -----------------------\n",
        "class ConvVAE(nn.Module):\n",
        "    def __init__(self, z_dim=...):\n",
        "        super().__init__()\n",
        "        # Encoder: 64 -> 32 -> 16 -> 8 -> 4\n",
        "        self.enc = nn.Sequential(\n",
        "            nn.Conv2d(3,  ..., 4, 2, 1),         nn.ReLU(True),             # 64x64 -> 32x32\n",
        "            nn.Conv2d(64, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.ReLU(True),  # -> 16x16\n",
        "            nn.Conv2d(...,256, 4, 2, 1), nn.BatchNorm2d(256), nn.ReLU(True),  # -> 8x8\n",
        "            nn.Conv2d(...,512, 4, 2, 1), nn.BatchNorm2d(512), nn.ReLU(True)   # -> 4x4\n",
        "        )\n",
        "        # TODO B2.1: FC layers to mean/logvar from flattened 512*4*4\n",
        "        self.fc_mu = nn.Linear(..., ...)\n",
        "        self.fc_lv = nn.Linear(..., ...)\n",
        "\n",
        "        # TODO B2.2: FC to expand from z_dim back to 512*4*4\n",
        "        self.fc_dec = nn.Linear(..., ...)\n",
        "\n",
        "        # Decoder: 4 -> 8 -> 16 -> 32 -> 64\n",
        "        self.dec = nn.Sequential(\n",
        "            nn.ConvTranspose2d(512,256,4,2,1), nn.BatchNorm2d(256), nn.ReLU(True),  # 4->8\n",
        "            nn.ConvTranspose2d(256,128,4,2,1), nn.BatchNorm2d(128), nn.ReLU(True),  # 8->16\n",
        "            nn.ConvTranspose2d(..., 64,4,2,1), nn.BatchNorm2d(64),  nn.ReLU(True),  # 16->32\n",
        "            nn.ConvTranspose2d(64,   3,4,2,1), nn.Sigmoid()                          # 32->64, [0,1]\n",
        "        )\n",
        "\n",
        "    def encode(self, x):\n",
        "        \"\"\"x -> (mu, lv)\"\"\"\n",
        "        # TODO B2.3: Flatten encoder features to [B, 512*4*4]\n",
        "        h = self.enc(x).view(x.size(0), -1)\n",
        "        return self.fc_mu(...), self.fc_lv(...)\n",
        "\n",
        "    def reparameterize(self, mu, lv):\n",
        "        \"\"\"z = mu + sigma * eps, where sigma = exp(0.5 * lv)\"\"\"\n",
        "        # TODO B2.4: Implement reparameterization\n",
        "        std = (0.5 * ...).exp()\n",
        "        eps = torch.randn_like(...)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def decode(self, z):\n",
        "        \"\"\"z -> x_hat in [0,1]\"\"\"\n",
        "        # TODO B2.5: Map z to [B,512,4,4], then deconvs\n",
        "        h = self.fc_dec(...).view(..., 512, 4, 4)\n",
        "        return self.dec(h)\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, lv = self.encode(x)\n",
        "        z = self.reparameterize(mu, lv)\n",
        "        recon = self.decode(z)\n",
        "        return recon, mu, lv\n",
        "\n",
        "# TODO B2.6: Instantiate ConvVAE and move to device\n",
        "model = ConvVAE(z_dim=...).to(device)\n"
      ],
      "metadata": {
        "id": "FBGjtaN7MxSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# -----------------------\n",
        "# 8) Loss (β-VAE ready)\n",
        "# -----------------------\n",
        "def vae_loss_conv(recon, x, mu, lv, beta=...):\n",
        "    \"\"\"Use BCE recon on [0,1] images + analytic KL. Return total,bce,kld per-example averages.\"\"\"\n",
        "    b = x.size(0)\n",
        "    # TODO B3.1: BCE with sum, KL in closed form, scale KL by beta\n",
        "    bce = F.binary_cross_entropy(..., ..., reduction='sum')\n",
        "    kld = -0.5 * torch.sum(1 + ... - ... - ...)\n",
        "    return (... + beta * ...) / b, ... / b, ... / b\n"
      ],
      "metadata": {
        "id": "2m96kp32M0UG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# -----------------------\n",
        "# 9) Train (Conv VAE)\n",
        "# -----------------------\n",
        "# TODO B4.1: Choose epochs and optimizer hyperparams\n",
        "epochs = ...\n",
        "opt = torch.optim.Adam(model.parameters(), lr=..., betas=(..., ...))\n",
        "\n",
        "model.train()\n",
        "for ep in range(1, epochs+1):\n",
        "    total, total_bce, total_kld, n = 0.0, 0.0, 0.0, 0\n",
        "    for x, _ in dl:\n",
        "        x = x.to(device)\n",
        "        recon, mu, lv = model(x)\n",
        "        loss, bce, kld = vae_loss_conv(recon, x, mu, lv, beta=...)\n",
        "\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "        bs_ = x.size(0)\n",
        "        total     += loss.item() * bs_\n",
        "        total_bce += bce.item()  * bs_\n",
        "        total_kld += kld.item()  * bs_\n",
        "        n += bs_\n",
        "    print(f\"[CATS][Epoch {ep:03d}] loss={total/n:.3f} recon={total_bce/n:.3f} kl={total_kld/n:.3f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "hAyFjX-SNQsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# 10) Visualize (Conv VAE)   no todos here\n",
        "# -----------------------\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    z=torch.randn(64,128,device=device)\n",
        "    gen=model.decode(z).cpu()\n",
        "    x,_=next(iter(dl))\n",
        "    x=x.to(device)[:64]\n",
        "    r,_,_=model(x)\n",
        "    gen_grid=make_grid(gen,8)\n",
        "    inp_grid=make_grid(x.cpu(),8)\n",
        "    rec_grid=make_grid(r.cpu(),8)\n",
        "\n",
        "def show(t):\n",
        "    plt.figure(figsize=(6,6))\n",
        "    plt.axis('off')\n",
        "    plt.imshow(t.permute(1,2,0))\n",
        "show(inp_grid)\n",
        "show(rec_grid)\n",
        "\n"
      ],
      "metadata": {
        "id": "WkTdDb-wNR4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# OPTIONAL EXPLORATIONS\n",
        "# ============================================================\n",
        "# - TODO X1: β-VAE — try beta in {0.5, 1, 4, 10} and discuss recon vs. latent structure.\n",
        "# - TODO X2: Latent dim sweep — try z_dim ∈ {2, 16, 64, 128, 256}.\n",
        "# - TODO X3: Replace BCE with MSE; discuss differences in smoothness/sharpness.\n",
        "# - TODO X4: Latent traversal — fix z, vary one dimension in [-3, 3], visualize effect.\n",
        "# - TODO X5: Add simple augmentations (RandomHorizontalFlip) and observe robustness."
      ],
      "metadata": {
        "id": "GmC6M2uUNTYT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}